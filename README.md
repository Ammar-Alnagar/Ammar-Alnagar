
Hi there, I'm Ammar Alnagar ğŸ‘‹

<div align="center">  
<strong>LLM Systems Engineer | AI Infrastructure Developer | Deep Learning Researcher</strong>  Building scalable, production-ready AI systems for the next generation of intelligent applications.





</div>  
---

ğŸš€ About Me

Iâ€™m a Masters in Deep Learning & Artificial Intelligence student and LLM Systems Engineer passionate about end-to-end AI product development â€” from research to deployment. I focus on high-performance inference pipelines, retrieval-augmented generation (RAG), and multi-agent AI systems.

ğŸ”¬ Specialties: Large Language Model optimization, RLHF, RAG, and multi-agent architectures

ğŸ¦€ Core Skills: Rust, Python, C++ for AI infrastructure & back-end systems

âš¡ Strengths: Efficient inference, distributed AI, and low-latency serving

ğŸ¯ Vision: Democratizing access to advanced AI through open-source contributions



---

ğŸ† Key Highlights

ğŸš¢ Deployed scalable AI inference systems serving multi-billion parameter LLMs in production

ğŸ“š Published open-source AI tools & models on Hugging Face

ğŸ” Optimized RAG pipelines to reduce latency by >40% using vector DB tuning and caching strategies

ğŸ¤ Collaborated on multi-agent frameworks for complex orchestration and autonomous reasoning



---

ğŸ› ï¸ Tech Stack (Specialized for AI Systems)

Core Languages & Tools






LLM & AI Frameworks







RAG & Agents





Deployment & Infrastructure






---

ğŸ“Œ Featured Projects

AI Multi-Agent Framework â€“ Autonomous reasoning agents for multi-step decision making

Optimized RAG Pipeline â€“ High-speed knowledge retrieval with sub-second query times

LLM Deployment Toolkit â€“ Tools for serving and optimizing large models at scale



---

<div align="center">  
*"The best way to predict the future is to build it."*  
<br>  
ğŸ’¬ **Open to collaboration & research discussions**  
</div>  
---

