
# ðŸ‘‹ Ammar Alnagar  
**Senior GenAI Systems Engineer | Building lean, production-grade LLM infrastructure**

> *"If itâ€™s not fast, maintainable, or measurableâ€”it doesnâ€™t ship."*

I design and deploy **scalable LLM inference systems** and **advanced RAG pipelines**â€”with a hard preference for **Rust**, **CUDA-aware Python**, and **minimalist architecture**. No fluff. No over-engineering. Just systems that scale under load.

ðŸŽ“ **MSc in Artificial Intelligence**  
ðŸ“ Focus: **Inference engines (vLLM)**, **quantization**, **graph RAG**, **multi-agent orchestration**

---

## ðŸ”§ What I Build

- **Efficient LLM Serving**: Optimized vLLM deployments, quantized models (GGUF/AWQ), distillation pipelines  
- **Graph-Based RAG**: Neo4j + dense retrieval + cross-encoder reranking  
- **Multi-Agent Systems**: LangGraph & CrewAI for task decomposition and tool use  
- **RLHF Infrastructure**: From reward modeling to PPO fine-tuning in specialized domains  

---

## ðŸ›  Core Stack

| Category       | Tools                                                                 |
|----------------|-----------------------------------------------------------------------|
| **Languages**  | Rust, Python, C++ (CUDA)                                             |
| **Inference**  | vLLM, Candle, Mistral.rs, TorchServe                    |
| **RAG/Agents** | LangGraph, CrewAI, Qdrant, Neo4j                                     |
| **Infra**      | Docker, AWS (EC2/S3), FastAPI, Prometheus/Grafana                     |
| **Optimization**| AWQ, GGUF, Unsloth, PEFT, Accelerate                                 |

> I avoid bloated abstractions. If a system canâ€™t be audited in <500 lines of core logic, itâ€™s already too complex.

---

## ðŸŒ Open Source

- [Hugging Face](https://huggingface.co/Daemontatox): Benchmarked quantized models, RAG configs, inference recipes  
- [GitHub](https://github.com/Ammar-Alnagar): Rust/Python tooling for lean LLM deployment  

I contribute **working systems**, not just notebooks.

---

## ðŸ¤ Letâ€™s Work Together

Iâ€™m open to:
- **Collaborating** on open-source LLM infrastructure (especially Rust-based)
- **Research** in efficient serving, distillation, or RAG evaluation
- **Production consulting** for teams shipping real LLM products

ðŸ“§ **Reach out**: [ammaralnagar416@gmail.com](mailto:ammaralnagar416@gmail.com)  
*(No recruiters. No â€œquick calls.â€ Be specific about the problem.)*

---

<div align="center">

[![LinkedIn](https://img.shields.io/badge/LinkedIn-0077B5?style=flat-square&logo=linkedin&logoColor=white)](https://www.linkedin.com/in/ammar-alnagar-393413201/)
[![HuggingFace](https://img.shields.io/badge/HuggingFace-FFD21E?style=flat-square&logo=huggingface&logoColor=black)](https://huggingface.co/Daemontatox)
[![GitHub](https://img.shields.io/github/followers/Ammar-Alnagar?style=flat-square&logo=github)](https://github.com/Ammar-Alnagar)

*"Optimizing AI systems one inference at a time."*  
![Profile Views](https://komarev.com/ghpvc/?username=Ammar-Alnagar&color=blueviolet&style=flat-square)

</div>

---