
ğŸš€ Hi there, I'm Ammar Alnagar! ğŸ‘‹

Machine Learning Systems Engineer | LLM Researcher | AI Optimization Specialist
ğŸ”¬ Specializing in LLM Reasoning, Multimodal AI, GPU Optimization, and Quantization
âš¡ Currently focused on Triton, CUDA, and high-performance AI kernels


---

ğŸ§  About Me

ğŸ¤– Passionate about LLMs, VLLMs, and advanced reasoning techniques

âš¡ Optimizing AI workflows with Triton, CUDA, and quantization (GPTQ, AWQ)

ğŸ“œ Creator of Zireal, a reasoning-optimized LLM with efficient thought chains

ğŸ§© Building Spectrum, a vision-language AI to support autistic childrenâ€™s communication skills

ğŸš€ Exploring high-speed transformer inference and LLM acceleration



---

ğŸ”¬ Projects & Research

ğŸš€ Featured Projects

Zireal â€“ High-speed reasoning LLM optimized for structured inference

Llama 70B CogniLink â€“ Advanced SOTA reasoning model

Cogito-R1 â€“ Qwen2.5-32B fine-tuned for optimized reasoning


ğŸ›  Open-Source & Research

ğŸ”¥ LLM Quantization & Inference Optimization â€“ GPTQ, AWQ, FlexGen

ğŸ“ Triton GPU Kernels for Fast Transformer Computation

ğŸ“š Multimodal AI & Cognitive AI Workflows



---

âš™ï¸ Tech Stack

Core Specialties:






Programming Languages:





---

ğŸ“Š GitHub Stats & Contributions





---

ğŸ“« Connect With Me

ğŸ’» GitHub | ğŸ“œ LinkedIn | ğŸ¤— Huggingface


---

ğŸ Fun Fact

```

# First Triton kernel - Vector Addition  
import triton  
import triton.language as tl  

@triton.jit  
def vector_add(X, Y, Z, N: tl.constexpr):  
    pid = tl.program_id(axis=0)  
    offsets = pid * 128 + tl.arange(0, 128)  
    mask = offsets < N  
    x = tl.load(X + offsets, mask=mask)  
    y = tl.load(Y + offsets, mask=mask)  
    tl.store(Z + offsets, x + y, mask=mask)


```

> ğŸš€ Mastering GPU acceleration, one Triton kernel at a time!