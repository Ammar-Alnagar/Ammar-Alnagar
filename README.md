# ğŸš€ Hi there, I'm Ammar Alnagar! ğŸ‘‹  

**Senior Machine Learning Software Engineer** | **LLM Researcher** | **AI Systems Optimization Specialist**  
ğŸ”¬ Specializing in **LLM Reasoning**, **Multimodal AI**, **Quantization**, and **High-Performance AI Kernels**  
âš¡ Currently focused on **Triton, PyTorch, CUDA, and Sub-4-Bit LLM Quantization**  

---

## ğŸ§  About Me  
- ğŸ¤– Passionate about **LLMs, VLLMs, and advanced reasoning techniques**   
- ğŸ“œ Creator of **Zireal**, a reasoning-optimized LLM with structured inference  
- ğŸ§© Building **VisoLearn**, a vision-language AI to enhance communication skills in autistic children  
- ğŸš€ Exploring **LLM acceleration, reinforcement learning, and Rust for AI optimization**  

---

## ğŸ”¬ Projects & Research  

### ğŸš€ Featured Projects  
- **[Zireal](https://huggingface.co/Daemontatox/Zireal-0)** â€“ A high-speed reasoning LLM optimized for structured inference  
- **[Llama 70B CogniLink](https://huggingface.co/Daemontatox/Llama3.3-70B-CogniLink)** â€“ An advanced SOTA reasoning model  
- **[Cogito-R1](https://huggingface.co/Daemontatox/Cogito-R1)** â€“ Qwen2.5-32B fine-tuned for optimized reasoning  

### ğŸ›  Open-Source & Research  
- ğŸ”¥ **LLM Quantization & Inference Optimization** â€“ GPTQ, AWQ, FlexGen, Sub-4-Bit Quantization  
- ğŸ“ **Triton GPU Kernels for Optimized Transformer Computation**  
- ğŸ“š **Multimodal AI, Cognitive AI, and Agentic Workflows**  
- ğŸš€ **Rust & Zig for High-Performance AI Applications**  

---

## âš™ï¸ Tech Stack & Languages  

### ğŸ’» Programming Languages  
- ![Python](https://img.shields.io/badge/Python-FFD43B?style=flat&logo=python&logoColor=blue)  
- ![C](https://img.shields.io/badge/C-00599C?style=flat&logo=c&logoColor=white)  
- ![C++](https://img.shields.io/badge/C++-00599C?style=flat&logo=c%2B%2B&logoColor=white)  
- ![Rust](https://img.shields.io/badge/Rust-000000?style=flat&logo=rust&logoColor=white)  
- ![Zig](https://img.shields.io/badge/Zig-F7A41D?style=flat&logo=zig&logoColor=black)  

### ğŸ›  AI & ML Frameworks  
- ![PyTorch](https://img.shields.io/badge/PyTorch-EE4C2C?style=flat&logo=pytorch&logoColor=white)  
- ![Triton](https://img.shields.io/badge/Triton-3498DB?style=flat&logo=triton&logoColor=white)  
- ![CUDA](https://img.shields.io/badge/CUDA-76B900?style=flat&logo=nvidia&logoColor=white)  
- ![TensorRT](https://img.shields.io/badge/TensorRT-76B900?style=flat&logo=nvidia&logoColor=white)  


### ğŸ“¡ System & Optimization Tools  
- ![Linux](https://img.shields.io/badge/Linux-FCC624?style=flat&logo=linux&logoColor=black)  
- ![Docker](https://img.shields.io/badge/Docker-2496ED?style=flat&logo=docker&logoColor=white)  
- ![LLVM](https://img.shields.io/badge/LLVM-555555?style=flat&logo=llvm&logoColor=white)  

---


<br clear="both">

<img src="https://raw.githubusercontent.com/Ammar-Alnagar/Ammar-Alnagar/output/snake.svg" alt="Snake animation" />

---
---

## ğŸ“« Connect With Me  
ğŸ’» [GitHub](https://github.com/Ammar-Alnagar) | ğŸ“œ [LinkedIn](https://www.linkedin.com/in/ammar-alnagar-393413201/) | ğŸ¤— [Huggingface](https://huggingface.co/Daemontatox)  

---



---

### ğŸ”¥ Latest Updates  
- ğŸ“Œ Deep dive into **Triton + PyTorch for AI kernel optimization**  
- ğŸš€ Researching **LLM sub-4-bit quantization and low-bit inference**  
- âš¡ Exploring **Rust and Zig for AI system optimization**  

---
