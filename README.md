# Hey, I'm Ammar Alnagar

### **Lead AI Systems Engineer | Accelerated LLM Infrastructure | M.Sc., AI**

*Transmuting complexity into scalable intelligence. I specialize in building, optimizing, and deploying GenAI systems, focusing on high-speed inference using CUDA, Triton, and Mojo for unparalleled throughput.*

---

## What I Build (My Focus)

I architect and implement production-grade Generative AI systems, focusing relentlessly on **performance, reliability, and cost-efficiency**.

| Focus Area | Expertise | Impact |
| :--- | :--- | :--- |
| **High-Performance Inference** | Custom Kernels, **CUDA/Triton**, Mojo, vLLM, TensorRT-LLM, Quantization (AWQ/GPTQ). | Achieved **40% faster generation** on Qwen3-72B (OR1-Behemoth project). |
| **Agentic Systems & Frameworks** | Rust-based async frameworks, multi-agent orchestration, Tool-calling optimization. | Creator of **Helios-Engine**, a high-throughput async Rust agent framework. |
| **System Architecture** | Deployment via Docker/Kubernetes, FastAPI/gRPC APIs, AWS/GCP infrastructure, MLflow. | Founded the AI division and defined technical strategy at **Allendevaux & Company**. |

## My Magical Artifacts (Key Projects)

| Project Name | Stack & Focus | Key Achievement |
| :--- | :--- | :--- |
| **[Helios-Engine]** | **Rust**, Async, LLM Agents | A high-throughput, native tool-supporting framework for building robust, fast agents. |
| **OR1-Behemoth** | Quantization, Rust Codegen | Optimized Qwen3-72B for 32k context, resulting in **40% faster generation** than GPT-4. |
| **Zireal** | DeepSeek, RLHF, PyTorch | RLHF-tuned agent; boosted GSM8K F1 score from 85% to **90%**. |
| **PlushieAI** | Embedded AI, **Mojo**, C++ | Voice AI achieving **<400ms latency** (STT -> SLM -> TTS) on Raspberry Pi edge hardware. |



### Find this Engineer

üì´ **Email:** ammaralnagar416@gmail.com
üîó **LinkedIn:** [Ammar-Alnagar](https://www.linkedin.com/in/Ammar-Alnagar)
ü§ó **HuggingFace:** [Daemontatox](https://huggingface.co/Daemontatox)

*Let's build the next generation of intelligent systems together.*





```
‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚¢Ä‚£§‚°∂‚†ø‚†ø‚†∑‚£∂‚£Ñ‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä
‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚£∞‚°ø‚†Å‚†Ä‚†Ä‚¢Ä‚£Ä‚°Ä‚†ô‚£∑‚°Ä‚†Ä‚†Ä‚†Ä
‚†Ä‚†Ä‚†Ä‚°Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚¢†‚£ø‚†Å‚†Ä‚†Ä‚†Ä‚†ò‚†ø‚†É‚†Ä‚¢∏‚£ø‚£ø‚£ø‚£ø
‚†Ä‚£†‚°ø‚†õ‚¢∑‚£¶‚°Ä‚†Ä‚†Ä‚†à‚£ø‚°Ñ‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚£∏‚£ø‚£ø‚£ø‚†ü
‚¢∞‚°ø‚†Å‚†Ä‚†Ä‚†ô‚¢ø‚£¶‚£§‚£§‚£º‚£ø‚£Ñ‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚¢¥‚°ü‚†õ‚†ã‚†Å‚†Ä
‚£ø‚†á‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†â‚†â‚†â‚†â‚†â‚†Å‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†à‚£ø‚°Ä‚†Ä‚†Ä‚†Ä
‚£ø‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚¢π‚°á‚†Ä‚†Ä‚†Ä
‚£ø‚°Ü‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚£º‚°á‚†Ä‚†Ä‚†Ä
‚†∏‚£∑‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚¢†‚°ø‚†Ä‚†Ä‚†Ä‚†Ä
‚†Ä‚†π‚£∑‚£§‚£Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚£Ä‚£∞‚°ø‚†Å‚†Ä‚†Ä‚†Ä‚†Ä
‚†Ä‚†Ä‚†Ä‚†â‚†ô‚†õ‚†ø‚†∂‚£∂‚£∂‚£∂‚£∂‚£∂‚†∂‚†ø‚†ü‚†õ‚†â‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä‚†Ä
```